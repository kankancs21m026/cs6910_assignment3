{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Assignment3_Master_QS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2vkvje2XA3r"
      },
      "source": [
        "# CS6910 Assignment 3 - Sujay and Avyay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0qCvgqBxzLo",
        "outputId": "9aa7a24b-21eb-41ab-b95c-1e25edae280e"
      },
      "source": [
        "!pip install wandb\n",
        "!pip install xtarfile\n",
        "!pip install pyenchant"
      ],
      "execution_count": 327,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.16)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.2.3)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.11)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: xtarfile in /usr/local/lib/python3.7/dist-packages (0.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "START_TOKEN=\"\\t\"\n",
        "END_TOKEN=\"\\n\""
      ],
      "metadata": {
        "id": "6xAqFEssB1RJ"
      },
      "execution_count": 328,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6xB0KDuy95e"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import wandb\n",
        "import re, string\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.font_manager import FontProperties\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from collections import Counter\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "import os\n",
        "from os.path import exists\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random \n",
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import xtarfile as tarfile\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 329,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t1O6AgVjPYm"
      },
      "source": [
        "# Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVMyzAmMzE1a",
        "outputId": "96dda63f-0b9e-4a4b-ba05-cb093de817ac"
      },
      "source": [
        "def downloadDataSet():\n",
        "   cwd = os.getcwd()\n",
        "  \n",
        "   file_exists = exists('./dakshina_dataset_v1.0.tar')\n",
        "   if(file_exists==False):\n",
        "     print('downloading....')\n",
        "     os.system('curl -SL https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar > dakshina_dataset_v1.0.tar')\n",
        "     print('download Complete')\n",
        "   extract_exists = exists('./dakshina_dataset_v1.0/')   \n",
        "   if(extract_exists==False): \n",
        "     print('Extracting..') \n",
        "     with tarfile.open('dakshina_dataset_v1.0.tar', 'r') as archive:\n",
        "         archive.extractall()\n",
        "     print('Complete')\n",
        "   print('You are all set')\n",
        "downloadDataSet()"
      ],
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are all set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlbXxZXZjpEq"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_files(language):\n",
        "\n",
        "  language='te'\n",
        "  train_dir='./dakshina_dataset_v1.0/'+language+'/lexicons/'+language+'.translit.sampled.train.tsv'\n",
        "  val_dir='./dakshina_dataset_v1.0/'+language+'/lexicons/'+language+'.translit.sampled.dev.tsv'\n",
        "  test_dir='./dakshina_dataset_v1.0/'+language+'/lexicons/'+language+'.translit.sampled.test.tsv'\n",
        "  \n",
        "  return train_dir, val_dir, test_dir\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3f4hq8zWCR41"
      },
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(lang,tokenizer=None):\n",
        "    \"\"\" Uses tf.keras tokenizer to tokenize the data/words into characters\n",
        "    \"\"\"\n",
        "    if(tokenizer==None):\n",
        "        tokenizer = Tokenizer(char_level=True)\n",
        "        tokenizer.fit_on_texts(lang)\n",
        "        lang_tensor = tokenizer.texts_to_sequences(lang)\n",
        "        lang_tensor = tf.keras.preprocessing.sequence.pad_sequences(lang_tensor,\n",
        "                                                            padding='post')\n",
        "    else:\n",
        "  \n",
        "        lang_tensor = tokenizer.texts_to_sequences(lang)\n",
        "        lang_tensor = tf.keras.preprocessing.sequence.pad_sequences(lang_tensor,\n",
        "                                                        padding='post')\n",
        "\n",
        "    return lang_tensor, tokenizer"
      ],
      "metadata": {
        "id": "gEO2ezOiD9cG"
      },
      "execution_count": 332,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC_zHEatTLsT"
      },
      "source": [
        "def preprocess_data(fpath,ip_tokenizer=None, tgt_tokenizer=None):\n",
        "    \"\"\" Reads, tokenizes and adds SOS/EOS tokens to data based on above functions\n",
        "    \"\"\"\n",
        "    #Read data from files\n",
        "    df = pd.read_csv(fpath, sep=\"\\t\", header=None)\n",
        "\n",
        "    #Add start and end token\n",
        "    df[0] = df[0].apply( lambda x:START_TOKEN+x+END_TOKEN) \n",
        "    ip_tensor, ip_tokenizer = tokenize(df[1].astype(str).tolist(), tokenizer=ip_tokenizer)\n",
        "    \n",
        "    tgt_tensor, tgt_tokenizer = tokenize(df[0].astype(str).tolist(), tokenizer=tgt_tokenizer) \n",
        "    \n",
        "    dataset = tf.data.Dataset.from_tensor_slices((ip_tensor, tgt_tensor))\n",
        "    dataset = dataset.shuffle(len(dataset))\n",
        "    \n",
        "    return dataset, ip_tokenizer, tgt_tokenizer\n",
        "\n"
      ],
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "language=\"te\"\n",
        "train_dir, val_dir, test_dir = get_files(language)\n",
        "\n",
        "dataset, input_tokenizer, targ_tokenizer = preprocess_data(train_dir)\n",
        "val_dataset, _, _ = preprocess_data(val_dir)\n"
      ],
      "metadata": {
        "id": "IOJaWA98T_ib"
      },
      "execution_count": 334,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train data \n",
        "dataset, input_tokenizer, targ_tokenizer = preprocess_data(train_dir)"
      ],
      "metadata": {
        "id": "EAEOyC7ggEpL"
      },
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjGJ1sFE-eon"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Utility functions ##\n",
        "def get_layer(name, units, dropout, return_state=False, return_sequences=False):\n",
        "\n",
        "    if name==\"rnn\":\n",
        "        return layers.SimpleRNN(units=units, dropout=dropout, \n",
        "                                return_state=return_state,\n",
        "                                return_sequences=return_sequences)\n",
        "\n",
        "    if name==\"gru\":\n",
        "        return layers.GRU(units=units, dropout=dropout, \n",
        "                          return_state=return_state,\n",
        "                          return_sequences=return_sequences)\n",
        "\n",
        "    if name==\"lstm\":\n",
        "        return layers.LSTM(units=units, dropout=dropout, \n",
        "                           return_state=return_state,\n",
        "                           return_sequences=return_sequences)\n"
      ],
      "metadata": {
        "id": "tk1aVpjVHz__"
      },
      "execution_count": 336,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLLikr1QN4kE"
      },
      "source": [
        "\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, enc_state, enc_out):\n",
        "    \n",
        "    enc_state = tf.concat(enc_state, 1)\n",
        "    enc_state = tf.expand_dims(enc_state, 1)\n",
        "\n",
        "    score = self.V(tf.nn.tanh(self.W1(enc_state) + self.W2(enc_out)))\n",
        "\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    context_vector = attention_weights * enc_out\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights\n",
        "\n"
      ],
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, cell_type, n_layers, units, encoder_vocab_size, embedding_dim, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layer_type = cell_type\n",
        "        self.n_layers = n_layers\n",
        "        self.units = units\n",
        "        self.dropout = dropout\n",
        "        self.embedding = tf.keras.layers.Embedding(encoder_vocab_size, embedding_dim)\n",
        "        self.create_rnn_layers()\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        x = self.rnn_layers[0](x, initial_state=hidden)\n",
        "\n",
        "        for layer in self.rnn_layers[1:]:\n",
        "            x = layer(x)\n",
        "\n",
        "        output, state = x[0], x[1:]\n",
        "\n",
        "        return output, state\n",
        "    \n",
        "    def create_rnn_layers(self):\n",
        "        self.rnn_layers = []\n",
        "\n",
        "        for i in range(self.n_layers):\n",
        "            self.rnn_layers.append(get_layer(self.layer_type, self.units, self.dropout,\n",
        "                                                return_sequences=True,\n",
        "                                                return_state=True))\n",
        "\n",
        "\n",
        "    def initialize_hidden_state(self, batch_size):\n",
        "\n",
        "        if self.layer_type != \"lstm\":\n",
        "            return [tf.zeros((batch_size, self.units))]\n",
        "        else:\n",
        "            return [tf.zeros((batch_size, self.units))]*2\n",
        "\n"
      ],
      "metadata": {
        "id": "omRnGooNH2ZM"
      },
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, layer_type, n_layers, units, decoder_vocab_size, embedding_dim, dropout, attention=False):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.layer_type = layer_type\n",
        "        self.n_layers = n_layers\n",
        "        self.units = units\n",
        "        self.dropout = dropout\n",
        "        self.attention = attention\n",
        "        self.embedding_layer = layers.Embedding(input_dim=decoder_vocab_size, \n",
        "                                                output_dim=embedding_dim)\n",
        "        \n",
        "        self.dense = layers.Dense(decoder_vocab_size, activation=\"softmax\")\n",
        "        self.flatten = layers.Flatten()\n",
        "        if self.attention:\n",
        "            self.attention_layer = BahdanauAttention(self.units)\n",
        "        self.create_rnn_layers()\n",
        "\n",
        "    def call(self, x, hidden, enc_out=None):\n",
        "        \n",
        "        x = self.embedding_layer(x)\n",
        "\n",
        "        if self.attention:\n",
        "            context_vector, attention_weights = self.attention_layer(hidden, enc_out)\n",
        "            x = tf.concat([tf.expand_dims(context_vector, 1), x], -1)\n",
        "        else:\n",
        "            attention_weights = None\n",
        "\n",
        "        x = self.rnn_layers[0](x, initial_state=hidden)\n",
        "\n",
        "        for layer in self.rnn_layers[1:]:\n",
        "            x = layer(x)\n",
        "\n",
        "        output, state = x[0], x[1:]\n",
        "\n",
        "        output = self.dense(self.flatten(output))\n",
        "        \n",
        "        return output, state, attention_weights\n",
        "\n",
        "    def create_rnn_layers(self):\n",
        "        self.rnn_layers = []    \n",
        "\n",
        "        for i in range(self.n_layers - 1):\n",
        "            self.rnn_layers.append(get_layer(self.layer_type, self.units, self.dropout,\n",
        "                                                return_sequences=True,\n",
        "                                                return_state=True))\n",
        "        \n",
        "        self.rnn_layers.append(get_layer(self.layer_type, self.units, self.dropout,\n",
        "                                            return_sequences=False,\n",
        "                                            return_state=True))"
      ],
      "metadata": {
        "id": "rh9-zphGH5vT"
      },
      "execution_count": 339,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lks31eDH0KKc"
      },
      "source": [
        "class BeamSearch():\n",
        "    def __init__(self, model, k):\n",
        "        self.k = k \n",
        "        self.model = model\n",
        "        self.acc = tf.keras.metrics.Accuracy()\n",
        "\n",
        "    def sample_beam_search(self, probs):\n",
        "\n",
        "        m, n = probs.shape\n",
        "        output_sequences = [[[], 0.0]]\n",
        "\n",
        "        for row in probs:\n",
        "            beams = []\n",
        "\n",
        "            for tup in output_sequences:\n",
        "                seq, score = tup\n",
        "                for j in range(n):\n",
        "                    new_beam = [seq + [j], score - tf.math.log(row[j])]\n",
        "                    beams.append(new_beam)\n",
        "\n",
        "            output_sequences = sorted(beams, key=lambda x: x[1])[:self.k]\n",
        "\n",
        "        tensors, scores = list(zip(*output_sequences))\n",
        "        tensors = list(map(lambda x: tf.expand_dims(tf.constant(x),0), tensors))\n",
        "\n",
        "        return tf.concat(tensors, 0), scores\n",
        "\n",
        "    def beam_accuracy(self, input, target):\n",
        "        accs = []\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.acc.reset_states()\n",
        "            self.acc.update_state(target, input[i, :])  \n",
        "            accs.append(self.acc.result())\n",
        "\n",
        "        return max(accs)\n",
        "    \n",
        "    def step(self, input, target, enc_state):\n",
        "\n",
        "        batch_acc = 0\n",
        "        sequences = []\n",
        "\n",
        "        enc_out, enc_state = self.model.encoder(input, enc_state)\n",
        "\n",
        "        dec_state = enc_state\n",
        "        dec_input = tf.expand_dims([self.model.targ_tokenizer.word_index[\"\\t\"]]*self.model.batch_size ,1)\n",
        "\n",
        "        for t in range(1, target.shape[1]):\n",
        "\n",
        "            preds, dec_state, _ = self.model.decoder(dec_input, dec_state, enc_out)\n",
        "\n",
        "            sequences.append(preds)\n",
        "            preds = tf.argmax(preds, 1)\n",
        "            dec_input = tf.expand_dims(preds, 1)\n",
        "\n",
        "        sequences = tf.concat(list(map(lambda x: tf.expand_dims(x, 1), sequences)), axis=1)\n",
        "\n",
        "        for i in range(target.shape[0]):\n",
        "\n",
        "            possibilities, scores = self.sample_beam_search(sequences[i, :, :])\n",
        "            batch_acc += self.beam_accuracy(possibilities, target[i, 1:])\n",
        "\n",
        "        batch_acc = batch_acc / target.shape[0]\n",
        "\n",
        "        return 0, batch_acc\n",
        "\n",
        "    def evaluate(self, test_dataset, batch_size=None, upto=5, use_wandb=False):\n",
        "        \n",
        "        if batch_size is not None:\n",
        "            self.model.batch_size = batch_size\n",
        "            test_dataset = test_dataset.batch(batch_size)\n",
        "        else:\n",
        "            self.model.batch_size = 1\n",
        "\n",
        "        test_acc = 0\n",
        "        enc_state = self.model.encoder.initialize_hidden_state(self.model.batch_size)\n",
        "\n",
        "        for batch, (input, target) in enumerate(test_dataset.take(upto)):\n",
        "           \n",
        "           _, acc = self.step(input, target, enc_state)\n",
        "           test_acc += acc\n",
        "\n",
        "        if use_wandb:\n",
        "            wandb.log({\"test acc (beam search)\": test_acc / upto})\n",
        "\n",
        "        print(f\"Test Accuracy on {upto*batch_size} samples: {test_acc / upto:.4f}\\n\")\n",
        "\n",
        "    def translate(self, word):\n",
        "\n",
        "        word = \"\\t\" + word + \"\\n\"\n",
        "        sequences = []\n",
        "        result = []\n",
        "\n",
        "        inputs = self.model.input_tokenizer.texts_to_sequences([word])\n",
        "        inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
        "                                                               maxlen=self.model.max_input_len,\n",
        "                                                               padding=\"post\")\n",
        "\n",
        "\n",
        "        enc_state = self.model.encoder.initialize_hidden_state(1)\n",
        "        enc_out, enc_state = self.model.encoder(inputs, enc_state)\n",
        "\n",
        "        dec_state = enc_state\n",
        "        dec_input = tf.expand_dims([self.model.targ_tokenizer.word_index[\"\\t\"]]*1, 1)\n",
        "\n",
        "        for t in range(1, self.model.max_target_len):\n",
        "\n",
        "            preds, dec_state, _ = self.model.decoder(dec_input, dec_state, enc_out)\n",
        "\n",
        "            sequences.append(preds)\n",
        "            preds = tf.argmax(preds, 1)\n",
        "            dec_input = tf.expand_dims(preds, 1)\n",
        "\n",
        "        sequences = tf.concat(list(map(lambda x: tf.expand_dims(x, 1), sequences)), axis=1)\n",
        "\n",
        "        possibilities, scores = self.sample_beam_search(tf.squeeze(sequences, 0))\n",
        "        output_words = self.model.targ_tokenizer.sequences_to_texts(possibilities.numpy())\n",
        "        \n",
        "        def post_process(word):\n",
        "            word = word.split(\" \")[:-1]\n",
        "            return \"\".join([x for x in word])\n",
        "\n",
        "        output_words = list(map(post_process, output_words))\n",
        "\n",
        "        return output_words, scores"
      ],
      "execution_count": 340,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Parameters():\n",
        "  def  __init__(self,  language='hi',encoder_layers=1,decoder_layers=1,embedding_dim=128,\\\n",
        "                layer_type='lstm', units=128, dropout=0.5, attention=False,batch_size=128,\\\n",
        "                apply_beam_search=False,teacher_forcing_ratio=1.0, save_outputs=None,epochs=5,wandb=False,beamWidth=5):\n",
        "        self.language = language\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.encoder_layers=encoder_layers\n",
        "        self.decoder_layers=decoder_layers\n",
        "        self.layer_type = layer_type\n",
        "        self.units = units\n",
        "        self.dropout = dropout\n",
        "        self.attention = attention\n",
        "        self.stats = []\n",
        "        self.wandb=wandb\n",
        "        self.epochs=epochs\n",
        "        self.batch_size = 128\n",
        "        self.apply_beam_search = apply_beam_search\n",
        "        self.batch_size = batch_size\n",
        "        self.teacher_forcing_ratio=teacher_forcing_ratio\n",
        "        self.save_outputs=save_outputs"
      ],
      "metadata": {
        "id": "ms98tmZIIFYa"
      },
      "execution_count": 352,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwR1miyeRrIG"
      },
      "source": [
        "from tqdm import tqdm\n",
        "class Seq2Seq():\n",
        "    def __init__(self, parameters):\n",
        "        self.embedding_dim = parameters.embedding_dim\n",
        "        self.encoder_layers = parameters.encoder_layers\n",
        "        self.decoder_layers = parameters.decoder_layers\n",
        "        self.layer_type = parameters.layer_type\n",
        "        self.units = parameters.units\n",
        "        self.dropout = parameters.dropout\n",
        "        self.attention = parameters.attention\n",
        "        self.stats = []\n",
        "        self.batch_size = parameters.batch_size\n",
        "        self.apply_beam_search = parameters.apply_beam_search\n",
        "    \n",
        "    def build(self, loss, optimizer, metric):\n",
        "        self.loss = loss\n",
        "        self.optimizer = optimizer\n",
        "        self.metric = metric\n",
        "\n",
        "    def set_vocabulary(self, input_tokenizer, targ_tokenizer):\n",
        "        self.input_tokenizer = input_tokenizer\n",
        "        self.targ_tokenizer = targ_tokenizer\n",
        "        self.create_model()\n",
        "    \n",
        "    def create_model(self):\n",
        "\n",
        "        encoder_vocab_size = len(self.input_tokenizer.word_index) + 1\n",
        "        decoder_vocab_size = len(self.targ_tokenizer.word_index) + 1\n",
        "\n",
        "        self.encoder = Encoder(self.layer_type, self.encoder_layers, self.units, encoder_vocab_size,\n",
        "                               self.embedding_dim, self.dropout)\n",
        "\n",
        "        self.decoder = Decoder(self.layer_type, self.decoder_layers, self.units, decoder_vocab_size,\n",
        "                               self.embedding_dim,  self.dropout, self.attention)\n",
        "\n",
        "    @tf.function\n",
        "    def train(self, input, target, enc_state):\n",
        "\n",
        "        loss = 0 \n",
        "\n",
        "        with tf.GradientTape() as tape: \n",
        "\n",
        "            enc_out, enc_state = self.encoder(input, enc_state)\n",
        "\n",
        "            dec_state = enc_state\n",
        "            dec_input = tf.expand_dims([self.targ_tokenizer.word_index[\"\\t\"]]*self.batch_size ,1)\n",
        "\n",
        "            ## We use Teacher forcing to train the network\n",
        "            ## Each target at timestep t is passed as input for timestep t + 1\n",
        "\n",
        "            if random.random() < self.teacher_forcing_ratio:\n",
        "\n",
        "                for t in range(1, target.shape[1]):\n",
        "\n",
        "                    preds, dec_state, _ = self.decoder(dec_input, dec_state, enc_out)\n",
        "                    loss += self.loss(target[:,t], preds)\n",
        "                    self.metric.update_state(target[:,t], preds)\n",
        "                    \n",
        "                    dec_input = tf.expand_dims(target[:,t], 1)\n",
        "            \n",
        "            else:\n",
        "\n",
        "                for t in range(1, target.shape[1]):\n",
        "\n",
        "                    preds, dec_state, _ = self.decoder(dec_input, dec_state, enc_out)\n",
        "                    loss += self.loss(target[:,t], preds)\n",
        "                    self.metric.update_state(target[:,t], preds)\n",
        "\n",
        "                    preds = tf.argmax(preds, 1)\n",
        "                    dec_input = tf.expand_dims(preds, 1)\n",
        "\n",
        "\n",
        "            batch_loss = loss / target.shape[1]\n",
        "\n",
        "            variables = self.encoder.variables + self.decoder.variables\n",
        "            gradients = tape.gradient(loss, variables)\n",
        "\n",
        "            self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "        return batch_loss, self.metric.result()\n",
        "\n",
        "    @tf.function\n",
        "    def validation(self, input, target, enc_state):\n",
        "\n",
        "        loss = 0\n",
        "        \n",
        "        enc_out, enc_state = self.encoder(input, enc_state)\n",
        "\n",
        "        dec_state = enc_state\n",
        "        dec_input = tf.expand_dims([self.targ_tokenizer.word_index[\"\\t\"]]*self.batch_size ,1)\n",
        "\n",
        "        for t in range(1, target.shape[1]):\n",
        "\n",
        "            preds, dec_state, _ = self.decoder(dec_input, dec_state, enc_out)\n",
        "            loss += self.loss(target[:,t], preds)\n",
        "            self.metric.update_state(target[:,t], preds)\n",
        "\n",
        "            preds = tf.argmax(preds, 1)\n",
        "            dec_input = tf.expand_dims(preds, 1)\n",
        "\n",
        "        batch_loss = loss / target.shape[1]\n",
        "        \n",
        "        return batch_loss, self.metric.result()\n",
        "\n",
        "\n",
        "    def fit(self, dataset, val_dataset, batch_size=128, epochs=5, wandb=False, teacher_forcing_ratio=1.0):\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
        "\n",
        "        steps_per_epoch = len(dataset) // self.batch_size\n",
        "        steps_per_epoch_val = len(val_dataset) // self.batch_size\n",
        "        \n",
        "        dataset = dataset.batch(self.batch_size, drop_remainder=True)\n",
        "        val_dataset = val_dataset.batch(self.batch_size, drop_remainder=True)\n",
        "\n",
        "        # useful when we need to translate the sentence\n",
        "        sample_inp, sample_targ = next(iter(dataset))\n",
        "        self.max_target_len = sample_targ.shape[1]\n",
        "        self.max_input_len = sample_inp.shape[1]\n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "        for epoch in  tqdm(range(1, epochs+1), total = epochs,desc=\"Epochs \"):\n",
        "           \n",
        "\n",
        "            ## Training loop ##\n",
        "            total_loss = 0\n",
        "            total_acc = 0\n",
        "            self.metric.reset_states()\n",
        "\n",
        "            starting_time = time.time()\n",
        "            enc_state = self.encoder.initialize_hidden_state(self.batch_size)\n",
        "\n",
        "           \n",
        "            for batch, (input, target) in enumerate(dataset.take(steps_per_epoch)):\n",
        "                batch_loss, acc = self.train(input, target, enc_state)\n",
        "                total_loss += batch_loss\n",
        "                total_acc += acc\n",
        "\n",
        "            avg_acc = total_acc / steps_per_epoch\n",
        "            avg_loss = total_loss / steps_per_epoch\n",
        "\n",
        "            # Validation loop ##\n",
        "            total_val_loss = 0\n",
        "            total_val_acc = 0\n",
        "            self.metric.reset_states()\n",
        "\n",
        "            enc_state = self.encoder.initialize_hidden_state(self.batch_size)\n",
        "\n",
        "            \n",
        "            for batch, (input, target) in enumerate(val_dataset.take(steps_per_epoch_val)):\n",
        "                batch_loss, acc = self.validation(input, target, enc_state)\n",
        "                total_val_loss += batch_loss\n",
        "                total_val_acc += acc\n",
        "\n",
        "            avg_val_acc = total_val_acc / steps_per_epoch_val\n",
        "            avg_val_loss = total_val_loss / steps_per_epoch_val\n",
        "\n",
        "            print( \"\\nTrain Loss: {0:.4f} Train Accuracy: {1:.4f} Validation Loss: {2:.4f} Validation Accuracy: {3:.4f}\".format(avg_loss, avg_acc*100, avg_val_loss, avg_val_acc*100))\n",
        "            \n",
        "            time_taken = time.time() - starting_time\n",
        "            self.stats.append({\"epoch\": epoch,\n",
        "                            \"train loss\": avg_loss,\n",
        "                            \"val loss\": avg_val_loss,\n",
        "                            \"train acc\": avg_acc*100,\n",
        "                            \"val acc\": avg_val_acc*100,\n",
        "                            \"training time\": time_taken})\n",
        "            \n",
        "            if wandb:\n",
        "                wandb.log(self.stats[-1])\n",
        "            \n",
        "            print(f\"\\nTime taken for the epoch {time_taken:.4f}\")\n",
        "           \n",
        "        \n",
        "        print(\"\\nModel trained successfully !!\")\n",
        "        \n",
        "    def evaluate(self, test_dataset, batch_size=None):\n",
        "\n",
        "        if batch_size is not None:\n",
        "            self.batch_size = batch_size\n",
        "\n",
        "        steps_per_epoch_test = len(test_dataset) // batch_size\n",
        "        test_dataset = test_dataset.batch(batch_size, drop_remainder=True)\n",
        "        \n",
        "        total_test_loss = 0\n",
        "        total_test_acc = 0\n",
        "        self.metric.reset_states()\n",
        "\n",
        "        enc_state = self.encoder.initialize_hidden_state(self.batch_size)\n",
        "\n",
        "        print(\"\\nRunning test dataset through the model...\\n\")\n",
        "        for batch, (input, target) in enumerate(test_dataset.take(steps_per_epoch_test)):\n",
        "            batch_loss, acc = self.validation(input, target, enc_state)\n",
        "            total_test_loss += batch_loss\n",
        "            total_test_acc += acc\n",
        "\n",
        "        avg_test_acc = total_test_acc / steps_per_epoch_test\n",
        "        avg_test_loss = total_test_loss / steps_per_epoch_test\n",
        "    \n",
        "        print(f\"Test Loss: {avg_test_loss:.4f} Test Accuracy: {avg_test_acc:.4f}\")\n",
        "\n",
        "        return avg_test_loss, avg_test_acc\n",
        "\n",
        "\n",
        "    def translate(self, word, get_heatmap=False):\n",
        "\n",
        "        word = \"\\t\" + word + \"\\n\"\n",
        "\n",
        "        inputs = self.input_tokenizer.texts_to_sequences([word])\n",
        "        inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
        "                                                               maxlen=self.max_input_len,\n",
        "                                                               padding=\"post\")\n",
        "\n",
        "        result = \"\"\n",
        "        att_wts = []\n",
        "\n",
        "        enc_state = self.encoder.initialize_hidden_state(1)\n",
        "        enc_out, enc_state = self.encoder(inputs, enc_state)\n",
        "\n",
        "        dec_state = enc_state\n",
        "        dec_input = tf.expand_dims([self.targ_tokenizer.word_index[\"\\t\"]]*1, 1)\n",
        "\n",
        "        for t in range(1, self.max_target_len):\n",
        "\n",
        "            preds, dec_state, attention_weights = self.decoder(dec_input, dec_state, enc_out)\n",
        "            \n",
        "            if get_heatmap:\n",
        "                att_wts.append(attention_weights)\n",
        "            \n",
        "            preds = tf.argmax(preds, 1)\n",
        "            next_char = self.targ_tokenizer.index_word[preds.numpy().item()]\n",
        "            result += next_char\n",
        "\n",
        "            dec_input = tf.expand_dims(preds, 1)\n",
        "\n",
        "            if next_char == \"\\n\":\n",
        "                return result[:-1], att_wts[:-1]\n",
        "\n",
        "        return result[:-1], att_wts[:-1]\n",
        "\n",
        "    "
      ],
      "execution_count": 342,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPPCBrHukCMZ"
      },
      "source": [
        "\n",
        "\n",
        "def run_model_on_test_dataset(param):\n",
        "\n",
        "    ## Character level accuracy ##\n",
        "    test_dataset, _, _ = preprocess_data(test_dir, model.input_tokenizer, model.targ_tokenizer)\n",
        "    test_loss, test_acc = model.evaluate(test_dataset, batch_size=100)\n",
        "    print('Character level accuracy: '+str(test_acc.numpy()))\n",
        "\n",
        "    ##  Word level accuracy ##\n",
        "    test_tsv = pd.read_csv(test_dir, sep=\"\\t\", header=None)\n",
        "    inputs = test_tsv[1].astype(str).tolist()\n",
        "    targets = test_tsv[0].astype(str).tolist()\n",
        "   \n",
        "    outputs = []\n",
        "\n",
        "    for word in inputs:\n",
        "        outputs.append(model.translate(word)[0])\n",
        "\n",
        "    print(f\"Word level accuracy: {np.sum(np.asarray(outputs) == np.array(targets)) / len(outputs)}\")\n",
        "\n",
        "    if param.save_outputs is not None:\n",
        "        df = pd.DataFrame()\n",
        "        df[\"inputs\"] = inputs\n",
        "        df[\"targets\"] = targets\n",
        "        df[\"outputs\"] = outputs\n",
        "        df.to_csv(param.save_outputs)\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "#randomly_evaluate(model, n=15)"
      ],
      "execution_count": 343,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param=Parameters(language=\"te\",\\\n",
        "                        embedding_dim=64,\\\n",
        "                        encoder_layers=3,\\\n",
        "                        decoder_layers=2,\\\n",
        "                        layer_type=\"lstm\",\\\n",
        "                        units=512,\\\n",
        "                        dropout=0.5,\n",
        "                        epochs=25\\\n",
        "                   )"
      ],
      "metadata": {
        "id": "yN7qrfXUFB7n"
      },
      "execution_count": 353,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzkdsWRlZzTf"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "model = Seq2Seq(param)\n",
        "model.set_vocabulary(input_tokenizer, targ_tokenizer)\n",
        "model.build(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                metric = tf.keras.metrics.SparseCategoricalAccuracy())\n",
        "\n",
        "model.fit(dataset, val_dataset, epochs=param.epochs, wandb=param.wandb, teacher_forcing_ratio=param.teacher_forcing_ratio)                  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = run_model_on_test_dataset(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFmGugnVYw1o",
        "outputId": "9fe8f316-7460-4ddf-a0f4-0e5dcd38df73"
      },
      "execution_count": 346,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running test dataset through the model...\n",
            "\n",
            "Test Loss: 1.1889 Test Accuracy: 0.8956\n",
            "Character level accuracy: 0.8955958\n",
            "Word level accuracy: 0.4793805463720202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate_samples(model, n=0):\n",
        "\n",
        "    df = pd.read_csv(test_dir, sep=\"\\t\", header=None)\n",
        "\n",
        "    printLine=True\n",
        "    source=[]\n",
        "    actual=[]\n",
        "    predict=[]\n",
        "    if(n==0):\n",
        "      print(f\"Evaluating the model on all words\\n\")\n",
        "      n=len(df)\n",
        "      printLine=False\n",
        "    else:\n",
        "      df = df.sample(n=n).reset_index(drop=True)\n",
        "      #print(f\"Randomly evaluating the model on {n} words\\n\")\n",
        "\n",
        "    for i in range(n):\n",
        "        word = str(df[1][i])\n",
        "        source.append(word)\n",
        "        actual.append(str(df[0][i]))\n",
        "        predict.append(model.translate(word)[0])\n",
        "        \"\"\"if(printLine):\n",
        "          print(f\"Input word: {word}\")\n",
        "          print(f\"Actual translation: {str(df[0][i])}\")\n",
        "          print(f\"Model translation: {predict[-1]}\\n\")\"\"\"\n",
        "    return source,actual,predict\n",
        "    "
      ],
      "metadata": {
        "id": "gziDZyElL7xe"
      },
      "execution_count": 472,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source,actual,predict=evaluate_samples(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qBSXHqxSmZu",
        "outputId": "e27d40c7-0cb6-4591-cc74-29f9e3dd183a"
      },
      "execution_count": 400,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating the model on all words\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML as html_print\n",
        "from IPython.display import display\n",
        "def compare_result(predict,actual,word):\n",
        "    string1=list(actual)\n",
        "    string2=list(predict)\n",
        "    maxstr=None\n",
        "    \n",
        "    minstr=None\n",
        "    if(len(string1)>len(string2)):\n",
        "      maxstr=string1\n",
        "      minstr=string2\n",
        "    else:\n",
        "      maxstr=string2\n",
        "      minstr=string1\n",
        "   \n",
        "    shift=0\n",
        "    html_str = \"\"\"\n",
        "    <br>\n",
        "      <table style=\"border:2px solid black; border-collapse:collapse\">\n",
        "      <tr>\n",
        "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;color:white;padding:10px;text-align:left\"> <strong>{}</strong> </td>\n",
        "      \"\"\".format(actual)\n",
        "    maxlen=len(maxstr)\n",
        "    minlen=len(minstr)\n",
        "    char_html=\"\"\n",
        "    j=0\n",
        "    for i in range(maxlen):\n",
        "    \n",
        "        if(j<minlen):\n",
        "          if(maxstr[i]==minstr[j]):\n",
        "              char_html+=\"\"\"<td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>{}</strong> </td>\"\"\".format(maxstr[i] )\n",
        "              j+=1\n",
        "          else:\n",
        "             if(i+1<maxlen and  maxstr[i+1]==minstr[j]):\n",
        "                char_html+=\"\"\" <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>{}</strong> </td>\"\"\".format(maxstr[i] )\n",
        "                continue\n",
        "             else:\n",
        "              j+=1\n",
        "              char_html+=\"\"\" <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>{}</strong> </td>\"\"\".format(maxstr[i] )\n",
        "        else:\n",
        "          char_html+=\"\"\"<td scope=\"row\" style=\"background-color: #FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>{} </strong></td>\"\"\".format(maxstr[i] )   \n",
        "\n",
        "    char_html+=\"\"\"</tr>\"\"\"\n",
        "    char_html+=\"\"\"<tr>\n",
        "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;padding:15px;color:white;text-align:left\"> <strong>{} </strong></td>\"\"\".format(predict)\n",
        "\n",
        "    j=0\n",
        "    for i in range(maxlen):\n",
        "\n",
        "        if(j<minlen):\n",
        "        \n",
        "          if(maxstr[i]==minstr[j]):\n",
        "            char_html+=\"\"\"<td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> {} </strong></td>\"\"\".format(minstr[j] )\n",
        "            j+=1\n",
        "          else:\n",
        "             if(i+1<maxlen and  maxstr[i+1]==minstr[j]):\n",
        "                char_html+=\"\"\"<td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>{}</strong> </td>\"\"\".format(' ' )\n",
        "                continue\n",
        "             else:\n",
        "                \n",
        "                char_html+=\"\"\"<td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>{}</strong> </td>\"\"\".format(minstr[j] )\n",
        "                j+=1\n",
        "        else:\n",
        "          char_html+=\"\"\"<td scope=\"row\" style=\"background-color:#FFF6F7  ; border:1px solid black;padding:15px;text-align:left\"><strong> {}</strong> </td>\"\"\".format('' )\n",
        "\n",
        "\n",
        "\n",
        "    char_html+=\"\"\"</tr>\"\"\"\n",
        "\n",
        "    char_html+=\"\"\"<tr>\n",
        "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;padding:15px;color:white;text-align:left\"> <strong>{} </strong></td>\"\"\".format(word)\n",
        "\n",
        "\n",
        "    j=0\n",
        "    for i in range(maxlen):\n",
        "    \n",
        "        if(j<minlen):\n",
        "          if(maxstr[i]==minstr[j]):\n",
        "              char_html+=\"\"\"<td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td>\"\"\"\n",
        "              j+=1\n",
        "          else:\n",
        "              if(i+1<maxlen and  maxstr[i+1]==minstr[j]):\n",
        "                char_html+=\"\"\"<td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td>\"\"\" \n",
        "                continue\n",
        "              else:\n",
        "                j+=1\n",
        "                char_html+=\"\"\" <td scope=\"row\" style=\" border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td>\"\"\"\n",
        "        else:\n",
        "          char_html+=\"\"\"<td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td>\"\"\" \n",
        "\n",
        "\n",
        "    char_html+=\"\"\"</tr>\"\"\"\n",
        "    html_str+=char_html\n",
        "    display(html_print(html_str)) "
      ],
      "metadata": {
        "id": "-kZudXemaAti"
      },
      "execution_count": 485,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_rnd,actual_rnd,predict_rnd=evaluate_samples(model,10)\n",
        "\n",
        "for i,j,k in zip(source_rnd,actual_rnd,predict_rnd):\n",
        "    compare_result(j,k,i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZM4_gZep1HQZ",
        "outputId": "a28cfbb4-56f6-4a2f-cc41-2bd70a963850"
      },
      "execution_count": 486,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <br>\n",
              "      <table style=\"border:2px solid black; border-collapse:collapse\">\n",
              "      <tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;color:white;padding:10px;text-align:left\"> <strong>ఆస్ట్రీలోలోని</strong> </td>\n",
              "      <td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ఆ</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>స</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>్</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ట</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>్</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ర</strong> </td> <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ే</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ల</strong> </td> <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ి</strong> </td> <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>య</strong> </td> <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ా</strong> </td> <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ల</strong> </td> <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ో</strong> </td><td scope=\"row\" style=\"background-color: #FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>న </strong></td><td scope=\"row\" style=\"background-color: #FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ి </strong></td></tr><tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;padding:15px;color:white;text-align:left\"> <strong>ఆస్ట్రేలియాలోని </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ఆ </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> స </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ్ </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ట </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ్ </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ర </strong></td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ీ</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ల </strong></td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ో</strong> </td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ల</strong> </td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ో</strong> </td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>న</strong> </td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ి</strong> </td><td scope=\"row\" style=\"background-color:#FFF6F7  ; border:1px solid black;padding:15px;text-align:left\"><strong> </strong> </td><td scope=\"row\" style=\"background-color:#FFF6F7  ; border:1px solid black;padding:15px;text-align:left\"><strong> </strong> </td></tr><tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;padding:15px;color:white;text-align:left\"> <strong>aastreliyaalooni </strong></td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td> <td scope=\"row\" style=\" border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td> <td scope=\"row\" style=\" border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td> <td scope=\"row\" style=\" border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td> <td scope=\"row\" style=\" border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td> <td scope=\"row\" style=\" border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td> <td scope=\"row\" style=\" border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td></tr>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <br>\n",
              "      <table style=\"border:2px solid black; border-collapse:collapse\">\n",
              "      <tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;color:white;padding:10px;text-align:left\"> <strong>పంచవభ్తం</strong> </td>\n",
              "      <td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ప</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ం</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>చ</strong> </td> <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>త</strong> </td> <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ం</strong> </td> <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>త</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>్</strong> </td> <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ర</strong> </td></tr><tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;padding:15px;color:white;text-align:left\"> <strong>పంచతంత్ర </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ప </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ం </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> చ </strong></td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>వ</strong> </td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>భ</strong> </td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong> </strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ్ </strong></td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>త</strong> </td></tr><tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;padding:15px;color:white;text-align:left\"> <strong>panchathanthra </strong></td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td> <td scope=\"row\" style=\" border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td> <td scope=\"row\" style=\" border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td> <td scope=\"row\" style=\" border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td></tr>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <br>\n",
              "      <table style=\"border:2px solid black; border-collapse:collapse\">\n",
              "      <tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;color:white;padding:10px;text-align:left\"> <strong>పునరావశం</strong> </td>\n",
              "      <td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ప</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ు</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>న</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ర</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ా</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>వ</strong> </td> <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ా</strong> </td> <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>స</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ం</strong> </td></tr><tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;padding:15px;color:white;text-align:left\"> <strong>పునరావాసం </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ప </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ు </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> న </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ర </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ా </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> వ </strong></td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>శ</strong> </td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong> </strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ం </strong></td></tr><tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;padding:15px;color:white;text-align:left\"> <strong>punaraavaasam </strong></td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td> <td scope=\"row\" style=\" border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td></tr>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <br>\n",
              "      <table style=\"border:2px solid black; border-collapse:collapse\">\n",
              "      <tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;color:white;padding:10px;text-align:left\"> <strong>ఎతిత్రుక్తం</strong> </td>\n",
              "       <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ఎ</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>త</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ి</strong> </td> <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>త</strong> </td> <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>్</strong> </td> <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ర</strong> </td> <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ు</strong> </td> <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>క</strong> </td> <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>్</strong> </td><td scope=\"row\" style=\"background-color: #FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>త </strong></td><td scope=\"row\" style=\"background-color: #FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ం </strong></td></tr><tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;padding:15px;color:white;text-align:left\"> <strong>ఇతివృత్తం </strong></td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ఇ</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> త </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ి </strong></td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>వ</strong> </td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ృ</strong> </td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>త</strong> </td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>్</strong> </td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>త</strong> </td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ం</strong> </td><td scope=\"row\" style=\"background-color:#FFF6F7  ; border:1px solid black;padding:15px;text-align:left\"><strong> </strong> </td><td scope=\"row\" style=\"background-color:#FFF6F7  ; border:1px solid black;padding:15px;text-align:left\"><strong> </strong> </td></tr><tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;padding:15px;color:white;text-align:left\"> <strong>etivruttam </strong></td> <td scope=\"row\" style=\" border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td> <td scope=\"row\" style=\" border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td> <td scope=\"row\" style=\" border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td> <td scope=\"row\" style=\" border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td> <td scope=\"row\" style=\" border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td> <td scope=\"row\" style=\" border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td> <td scope=\"row\" style=\" border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td></tr>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <br>\n",
              "      <table style=\"border:2px solid black; border-collapse:collapse\">\n",
              "      <tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;color:white;padding:10px;text-align:left\"> <strong>పొలం</strong> </td>\n",
              "      <td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ప</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ొ</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ల</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ం</strong> </td></tr><tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;padding:15px;color:white;text-align:left\"> <strong>పొలం </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ప </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ొ </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ల </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ం </strong></td></tr><tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;padding:15px;color:white;text-align:left\"> <strong>polam </strong></td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td></tr>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <br>\n",
              "      <table style=\"border:2px solid black; border-collapse:collapse\">\n",
              "      <tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;color:white;padding:10px;text-align:left\"> <strong>ఈపాని</strong> </td>\n",
              "       <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ఈ</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ప</strong> </td> <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ా</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>న</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ి</strong> </td></tr><tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;padding:15px;color:white;text-align:left\"> <strong>ఏపని </strong></td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ఏ</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ప </strong></td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong> </strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> న </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ి </strong></td></tr><tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;padding:15px;color:white;text-align:left\"> <strong>epani </strong></td> <td scope=\"row\" style=\" border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td></tr>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <br>\n",
              "      <table style=\"border:2px solid black; border-collapse:collapse\">\n",
              "      <tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;color:white;padding:10px;text-align:left\"> <strong>సేకరించిన</strong> </td>\n",
              "      <td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>స</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ే</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>క</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ర</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ి</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ం</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>చ</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ి</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>న</strong> </td></tr><tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;padding:15px;color:white;text-align:left\"> <strong>సేకరించిన </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> స </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ే </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> క </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ర </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ి </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ం </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> చ </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ి </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> న </strong></td></tr><tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;padding:15px;color:white;text-align:left\"> <strong>saekarinchina </strong></td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td></tr>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <br>\n",
              "      <table style=\"border:2px solid black; border-collapse:collapse\">\n",
              "      <tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;color:white;padding:10px;text-align:left\"> <strong>వన్ని</strong> </td>\n",
              "      <td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>వ</strong> </td> <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ా</strong> </td> <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ణ</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>్</strong> </td> <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ణ</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ి</strong> </td></tr><tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;padding:15px;color:white;text-align:left\"> <strong>వాణ్ణి </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> వ </strong></td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>న</strong> </td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong> </strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ్ </strong></td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>న</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ి </strong></td></tr><tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;padding:15px;color:white;text-align:left\"> <strong>vanni </strong></td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td> <td scope=\"row\" style=\" border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td> <td scope=\"row\" style=\" border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td></tr>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <br>\n",
              "      <table style=\"border:2px solid black; border-collapse:collapse\">\n",
              "      <tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;color:white;padding:10px;text-align:left\"> <strong>ఈమాత్రం</strong> </td>\n",
              "       <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ఏ</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>మ</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ా</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>త</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>్</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ర</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ం</strong> </td></tr><tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;padding:15px;color:white;text-align:left\"> <strong>ఏమాత్రం </strong></td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ఈ</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> మ </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ా </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> త </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ్ </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ర </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ం </strong></td></tr><tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;padding:15px;color:white;text-align:left\"> <strong>aemaathram </strong></td> <td scope=\"row\" style=\" border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td></tr>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <br>\n",
              "      <table style=\"border:2px solid black; border-collapse:collapse\">\n",
              "      <tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;color:white;padding:10px;text-align:left\"> <strong>కరాచి</strong> </td>\n",
              "      <td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>క</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ర</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>ా</strong> </td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"> <strong>చ</strong> </td> <td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ీ</strong> </td></tr><tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;padding:15px;color:white;text-align:left\"> <strong>కరాచీ </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> క </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ర </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> ా </strong></td><td scope=\"row\" style=\"background-color:#E3FFE7 ;border:1px solid black;padding:15px;text-align:left\"><strong> చ </strong></td><td scope=\"row\" style=\"background-color:#FFF6F7 ; border:1px solid black;padding:15px;text-align:left\"> <strong>ి</strong> </td></tr><tr>\n",
              "      <td scope=\"row\" style=\"border:1px solid black;background-color:#3498DB;padding:15px;color:white;text-align:left\"> <strong>qarachi </strong></td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td><td scope=\"row\" style=\"border:1px solid black;padding:15px;text-align:left\">&#x2705; </td> <td scope=\"row\" style=\" border:1px solid black;padding:15px;text-align:left\"> &#x274C; </td></tr>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}